#!/bin/bash
# Ignition Startup Script - Simplified Edition
# Uses the same logic as download_models_once.sh for consistency

set -euo pipefail

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
WORKSPACE_ROOT="/workspace"
COMFYUI_ROOT="/workspace/ComfyUI"
LOG_FILE="/tmp/ignition_startup.log"

# Set up caches and paths early
export XDG_CACHE_HOME="${XDG_CACHE_HOME:-/workspace/.cache}"
export HF_HOME="${HF_HOME:-/workspace/.cache/huggingface}"
export HUGGINGFACE_HUB_CACHE="${HUGGINGFACE_HUB_CACHE:-$HF_HOME}"
mkdir -p "$HF_HOME" || true

# Consistent Python interpreter
PYBIN="$(command -v python3 || command -v python)"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Logging function
log() {
    local level=$1
    shift
    local message="$@"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    
    case $level in
        "INFO")
            echo -e "${GREEN}[INFO]${NC} $message" | tee -a "$LOG_FILE"
            ;;
        "WARN")
            echo -e "${YELLOW}[WARN]${NC} $message" | tee -a "$LOG_FILE"
            ;;
        "ERROR")
            echo -e "${RED}[ERROR]${NC} $message" | tee -a "$LOG_FILE"
            ;;
        *)
            echo -e "$message" | tee -a "$LOG_FILE"
            ;;
    esac
}

# Environment variable defaults
export CIVITAI_MODELS="${CIVITAI_MODELS:-}"
export HUGGINGFACE_MODELS="${HUGGINGFACE_MODELS:-}"
export CIVITAI_TOKEN="${CIVITAI_TOKEN:-}"
export HF_TOKEN="${HF_TOKEN:-}"
export FILEBROWSER_PASSWORD="${FILEBROWSER_PASSWORD:-runpod}"
export COMFYUI_PORT="${COMFYUI_PORT:-8188}"
export FILEBROWSER_PORT="${FILEBROWSER_PORT:-8080}"
export FORCE_MODEL_SYNC="${FORCE_MODEL_SYNC:-false}"

print_banner() {
    log "INFO" ""
    log "INFO" "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    log "INFO" "â•‘              ðŸš€ IGNITION v1.2            â•‘"
    log "INFO" "â•‘        ComfyUI Dynamic Model Loader      â•‘"
    log "INFO" "â•‘             SIMPLE EDITION               â•‘"
    log "INFO" "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    log "INFO" ""
}

print_config() {
    log "INFO" "ðŸ“‹ Configuration:"
    log "INFO" "  â€¢ CivitAI Models: ${CIVITAI_MODELS:-'None specified'}"
    log "INFO" "  â€¢ HuggingFace Models: ${HUGGINGFACE_MODELS:-'None specified'}"
    log "INFO" "  â€¢ Storage: RunPod volume (/workspace)"
    log "INFO" "  â€¢ ComfyUI Port: $COMFYUI_PORT"
    log "INFO" "  â€¢ File Browser Port: $FILEBROWSER_PORT"
    log "INFO" ""
}

check_system() {
    log "INFO" "ðŸ” Checking system requirements..."
    
    if [[ ! -d "$COMFYUI_ROOT" ]]; then
        log "ERROR" "ComfyUI directory not found: $COMFYUI_ROOT"
        exit 1
    fi
    
    if [[ ! -f "$SCRIPT_DIR/download_civitai_simple.py" ]] || [[ ! -f "$SCRIPT_DIR/download_huggingface_simple.py" ]] || [[ ! -x "$SCRIPT_DIR/download_models_once.sh" ]]; then
        log "ERROR" "Download scripts not found in $SCRIPT_DIR"
        exit 1
    fi
    
    # Check GPU availability
    if command -v nvidia-smi &> /dev/null; then
        GPU_INFO=$(nvidia-smi --query-gpu=name --format=csv,noheader,nounits | head -1 || echo "Unknown")
        log "INFO" "  â€¢ GPU Detected: $GPU_INFO"
    else
        log "WARN" "  â€¢ No NVIDIA GPU detected"
    fi
    
    log "INFO" "âœ… System requirements check complete"
    log "INFO" ""
}

setup_storage() {
    log "INFO" "ðŸ’¾ Setting up model directories..."
    
    mkdir -p "$COMFYUI_ROOT/models"/{checkpoints,loras,vae,embeddings,controlnet,upscale_models,diffusion_models,text_encoders,clip,unet}
    
    for model_type in checkpoints loras vae embeddings controlnet upscale_models diffusion_models text_encoders clip unet; do
        log "INFO" "  â€¢ Created $model_type directory"
    done
    
    log "INFO" "âœ… Model directories ready"
    log "INFO" ""
}

# Use the download_models_once.sh script for downloads
download_models() {
    if [[ -z "$CIVITAI_MODELS$HUGGINGFACE_MODELS" ]]; then
        log "INFO" "ðŸ“¥ No models requested; skipping downloads."
        log "INFO" ""
        return
    fi

    log "INFO" "ðŸ“¥ Starting model downloads..."
    if bash "$SCRIPT_DIR/download_models_once.sh"; then
        log "INFO" "âœ… Model downloads completed"
    else
        if [[ "${FORCE_MODEL_SYNC}" == "true" ]]; then
            log "ERROR" "Model download failed and FORCE_MODEL_SYNC=true"
            exit 3
        fi
        log "WARN" "âš ï¸ Some model downloads may have failed, continuing"
    fi
    log "INFO" ""
}

start_filebrowser() {
    log "INFO" "ðŸ“ Starting file browser..."
    
    local config_dir="$WORKSPACE_ROOT/.filebrowser"
    local db_path="$config_dir/filebrowser.db"
    mkdir -p "$config_dir"
    
    if [[ ! -f "$db_path" ]]; then
        log "INFO" "  â€¢ Initializing filebrowser database..."
        filebrowser -d "$db_path" config init
        
        local fb_password="$FILEBROWSER_PASSWORD"
        if [[ ${#fb_password} -lt 12 ]]; then
            fb_password="ignition_${FILEBROWSER_PASSWORD}_2024"
        fi
        
        filebrowser -d "$db_path" config set --auth.method=json --auth.header=""
        filebrowser -d "$db_path" users add admin "$fb_password" --perm.admin
        
        log "INFO" "  â€¢ Admin user created (password set; not logged)"
    fi
    
    log "INFO" "  â€¢ Starting filebrowser on port $FILEBROWSER_PORT"
    filebrowser \
        --database "$db_path" \
        --root "$WORKSPACE_ROOT" \
        --address "0.0.0.0" \
        --port "$FILEBROWSER_PORT" &
    
    log "INFO" "  â€¢ Login: admin (password not shown in logs)"
    log "INFO" ""
}

gpu_preflight() {
    log "INFO" "ðŸ”§ GPU preflight check..."

    # Be tolerant: nvidia-smi is informative only; never hard-fail here
    nvidia-smi -L || log "WARN" "nvidia-smi device listing failed; continuing"

    # Select first GPU by UUID if user hasn't pinned one
    if [[ -z "${CUDA_VISIBLE_DEVICES:-}" ]]; then
        first_uuid="$(nvidia-smi --query-gpu=uuid --format=csv,noheader | head -n1 2>/dev/null || true)"
        if [[ -n "$first_uuid" ]]; then
            export CUDA_VISIBLE_DEVICES="$first_uuid"
            log "INFO" "  â€¢ CUDA_VISIBLE_DEVICES set to first GPU UUID"
        else
            export CUDA_VISIBLE_DEVICES=0
            log "WARN" "  â€¢ UUID query empty; falling back to index 0"
        fi
    fi

    # Ensure driver libs are in path
    export LD_LIBRARY_PATH="/usr/local/nvidia/lib64:/usr/lib/x86_64-linux-gnu:${LD_LIBRARY_PATH:-}"

    # Use one Python everywhere
    log "INFO" "  â€¢ Using Python at: $PYBIN"

    # Single source of truth: PyTorch must see CUDA
    "$PYBIN" - <<'PY'
import torch, sys
print(f"[GPU] torch: {torch.__version__} cuda: {torch.version.cuda}")
ok = torch.cuda.is_available()
print(f"[GPU] cuda available: {ok}")
if not ok:
    sys.exit(2)
print(f"[GPU] device: {torch.cuda.get_device_name(0)} cap: {torch.cuda.get_device_capability(0)}")
PY
    rc=$?
    if [[ $rc -ne 0 ]]; then
        log "ERROR" "PyTorch CUDA initialization failed"
        exit 2
    fi

    log "INFO" "âœ… GPU preflight complete"
    log "INFO" ""
}

start_comfyui() {
    log "INFO" "ðŸŽ¨ Starting ComfyUI..."

    if command -v ss >/dev/null 2>&1 && ss -tulpn 2>/dev/null | grep -q ":$COMFYUI_PORT "; then
        log "ERROR" "Port $COMFYUI_PORT already in use"
        exit 4
    fi

    cd "$COMFYUI_ROOT"
    log "INFO" "  â€¢ Starting with CUDA support"
    exec "$PYBIN" main.py --listen "0.0.0.0" --port "$COMFYUI_PORT"
}

# Signal handlers
cleanup() {
    log "INFO" "ðŸ›‘ Shutting down Ignition..."
    jobs -p | xargs -r kill 2>/dev/null || true
    exit 0
}

trap cleanup SIGTERM SIGINT

# Main execution
main() {
    print_banner
    print_config
    check_system
    setup_storage
    download_models
    start_filebrowser
    gpu_preflight
    start_comfyui
}

main "$@"